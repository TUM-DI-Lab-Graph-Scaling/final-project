\subsection{Scalable Machine Learning}

Training data is getting increasingly larger and model architectures are getting more complex with increasing numbers 
of parameters. Scaling and parallelization of large-scale machine learning models play a key role in reaching peak 
performance and accuracy. In this chapter, we will discuss scaling strategies for deep learning models. 

\subsubsection{Scaling up vs. Scaling out}

Before scaling the training of a machine learning model, the question in which form the scaling should happen has to 
be answered. There are two fundamental types of scaling: \textit{scaling up} and \textit{scaling out}. When only the resources of the 
existing machine, on which the model is trained, are expanded in order to achieve better performance, we speak of 
scaling up.

On the other hand, if an increase in resources of a single machine is no longer technically possible or not possible for 
other reasons, the underlying resources must be increased in a different way. Distributing the training pipeline over 
several processes presents a way to further scale, whereby the processes can also be distributed over multiple machines. 
This is known as scaling out. 

A single machine multi-GPU setup is an interesting middle ground between scaling up and scaling out. Although the entire 
pipeline is executed on only one machine, we still employ a multi-process system since each of the GPUs is used through 
independent processes.

\subsubsection{Data, Model and Pipeline Parallelism}
\label{subsubsec:data-model-pipeline}

In our work, we used a scaling out approach to scale the existing pipelines. Three common scaling-out strategies have emerged 
in recent years for machine learning models. With a large amount of training data, long training on only a single 
machine becomes unfeasible. To scale the training to multiple devices, \textit{data parallelism} is used to partition and distribute 
the training data while replicating the model on each machine. Gradients are exchanged across machines after the backward 
pass, ensuring that all models will be in the same state at optimizer updates. 

When the model size exceeds the memory capacities of a single device, \textit{model parallelism} 
\cite*{10.48550/ARXIV.1811.02084, 10.48550/ARXIV.1909.08053} can be used to split model 
parameters among multiple processes, devices or even machines. A neural network architecture can be horizontally and vertically partitioned, 
whereby in horizontal partitioning each device holds different layers of the model and in vertical partitioning layers 
are cut internally and each device holds a part of each layer.

A disadvantage of the na\"ive implementation of model parallelism is the sequential execution of forward and backward passes 
through the layers. All other machines are forced to wait when a single machine is performing computations, often referred to 
as bubble overhead in literature. To avoid bubble overhead, a more advanced form of model parallelism known as \textit{pipeline parallelism}
was developed, in which the model is split horizontally and the communication between layers gets overlapped through micro-batches. 
Popular implementations of pipeline parallelism include G-Pipe \cite*{10.48550/ARXIV.1811.06965} and 
PipeDream \cite*{10.48550/ARXIV.1806.03377}. G-Pipe pipelines the execution of micro-batches accross machines, 
effectively overlapping executions of batches during forward and backward passes, while PipeDream intersperses the execution of 
forward and backward passes through more complex scheduling algorithms. 

